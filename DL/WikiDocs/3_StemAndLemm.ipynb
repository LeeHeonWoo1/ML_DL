{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어간 추출(Stemming)과 표제어 추출(Lemmatization)\n",
    "정규화 기법 중 코퍼스에 있는 단어의 개수를 줄일 수 있는 기법이다. 이 두 작업이 가지고 있는 핵심은 서로 다른 단어들 일지라도 하나의 단어로 일반화시킬 수 있다면 하나의 단어로 일반화하여 문서 내의 단어 수를 줄이겠다는 것이다. \n",
    "\n",
    "### 표제어 추출\n",
    "표제어는 한글로는 **표제어** 또는 **기본 사전형 단어** 정도의 의미를 갖습니다. 표제어 추출을 하는 가장 섬세한 방법은 단어의 형태학적 파싱을 먼저 진행하는 것입니다. 형태소란 '의미를 가진 가장 작은 단위'를 뜻합니다. 형태학이란 형태소로부터 단어를 만들어가는 학문을 의미합니다.\n",
    "\n",
    "- 어간(stem) : 단어의 의미를 담고 있는 단어의 핵심 부분\n",
    "- 접사(affix) : 단어에 추가적인 의미를 주는 부분\n",
    "\n",
    "ex. cats ➡️ cat(어간), -s(접사) | fox의 경우 독립적인 형태소라 더 분해되지 않는다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "표제어 추출 전 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "표제어 추출 후 : ['policy', 'doing', 'organization', 'have', 'going', 'love', 'life', 'fly', 'dy', 'watched', 'ha', 'starting']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print(f\"표제어 추출 전 : {words}\")\n",
    "print(f\"표제어 추출 후 : {[lemmatizer.lemmatize(word) for word in words]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dies는 dy, has는 ha로 추출하는 등의 잘못 추출되는 경우가 존재하는 것을 확인할 수 있다. 이는 표제어 추출기가 본래 단어의 품사 정보를 알아야만 정확한 정보를 얻을 수 있기 때문이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'die'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize(\"dies\", \"v\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'have'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('has', 'v')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'watch'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmatizer.lemmatize('watched', 'v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "표제어 추출은 문맥을 고려하여 수행했을 때의 결과는 해당 단어의 품사 정보를 보존합니다. 하지만 어간 추출을 수행한 결과는 품사 정보가 보존되지 않습니다. 더 정확히는 어간 추출을 한 결과는 사전에 존재하지 않는 단어일 경우가 많습니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 어간 추출\n",
    "어간을 추출하는 작업을 어간 추출이라고 한다. 어간 추출은 형태학적 분석을 단순화한 버전이라고 볼 수 있고, 정해진 규칙만 보고 단어의 어미를 자르는 어림짐작의 작업이라고 볼 수도 있다. 이 작업은 섬세한 작업이 아니기 때문에 어간 추출 후에 나오는 결과 단어는 사전에 존재하지 않는 단어일 수도 있다. 어간 추출 알고리즘 중 하나인 포터 알고리즘에 아래의 문자열을 입력으로 넣는 예제를 실행해보자."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 : ['This', 'was', 'not', 'the', 'map', 'we', 'found', 'in', 'Billy', 'Bones', \"'s\", 'chest', ',', 'but', 'an', 'accurate', 'copy', ',', 'complete', 'in', 'all', 'things', '--', 'names', 'and', 'heights', 'and', 'soundings', '--', 'with', 'the', 'single', 'exception', 'of', 'the', 'red', 'crosses', 'and', 'the', 'written', 'notes', '.']\n",
      "어간 추출 후 : ['thi', 'wa', 'not', 'the', 'map', 'we', 'found', 'in', 'billi', 'bone', \"'s\", 'chest', ',', 'but', 'an', 'accur', 'copi', ',', 'complet', 'in', 'all', 'thing', '--', 'name', 'and', 'height', 'and', 'sound', '--', 'with', 'the', 'singl', 'except', 'of', 'the', 'red', 'cross', 'and', 'the', 'written', 'note', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "stemmer = PorterStemmer()\n",
    "\n",
    "sentence = \"This was not the map we found in Billy Bones's chest, but an accurate copy, \\\n",
    "complete in all things--names and heights and soundings--with the single exception \\\n",
    "of the red crosses and the written notes.\"\n",
    "\n",
    "tokenized_sentence = word_tokenize(sentence)\n",
    "\n",
    "print(f\"어간 추출 전 : {tokenized_sentence}\")\n",
    "print(f\"어간 추출 후 : {[stemmer.stem(word) for word in tokenized_sentence]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "규칙 기반의 접근을 하고 있으므로 어간 추출 후의 결과에는 사전에 없는 단어들도 포함되어 있다. 포터 알고리즘의 어간 추출은 아래와 같은 규칙들을 가진다\n",
    "\n",
    "- ALIZE ➡️ AL\n",
    "- ANCE ➡️ 제거\n",
    "- ICAL ➡️ IC\n",
    "\n",
    "위의 규칙에 따르면 아래의 단어들은 아래와 같이 변환됩니다.\n",
    "- formalize = formal\n",
    "- allowance = allow\n",
    "- electricical = electric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 :  ['formalize', 'allowance', 'electricical']\n",
      "어간 추출 후 :  ['formal', 'allow', 'electric']\n"
     ]
    }
   ],
   "source": [
    "words = [\"formalize\", \"allowance\", \"electricical\"]\n",
    "\n",
    "print(\"어간 추출 전 : \", words)\n",
    "print(\"어간 추출 후 : \", [stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "어간 추출 속도는 표제어 추출보다 일반적으로 빠른데, 포터 어간 추출기는 정밀하게 설계되어 정확도가 높으므로 영어 자연어 처리에서 어간 추출을 하고자 한다면 가장 준수한 선택이다. NLTK에서는 포터 알고리즘 외에도 랭커스터 스태머 알고리즘을 지원한다. 이번에는 포터 알고리즘과 랭커스터 알고리즘으로 각각 어간 추출을 진행했을 때, 이 둘의 결과를 비교해본다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어간 추출 전 :  ['policy', 'doing', 'organization', 'have', 'going', 'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
      "포터 스테머의 어간 추출 후 :  ['polici', 'do', 'organ', 'have', 'go', 'love', 'live', 'fli', 'die', 'watch', 'ha', 'start']\n",
      "랭커스터 스테머의 어간 추출 후 :  ['policy', 'doing', 'org', 'hav', 'going', 'lov', 'liv', 'fly', 'die', 'watch', 'has', 'start']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import LancasterStemmer\n",
    "\n",
    "porter_stemmer = PorterStemmer()\n",
    "lancaster_stemmer = LancasterStemmer()\n",
    "\n",
    "words = ['policy', 'doing', 'organization', 'have', 'going', \n",
    "         'love', 'lives', 'fly', 'dies', 'watched', 'has', 'starting']\n",
    "\n",
    "print(\"어간 추출 전 : \", words)\n",
    "print(\"포터 스테머의 어간 추출 후 : \", [porter_stemmer.stem(word) for word in words])\n",
    "print(\"랭커스터 스테머의 어간 추출 후 : \", [lancaster_stemmer.stem(word) for word in words])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "동일한 단어들의 나열에 대해서 두 스태머는 전혀 다른 결과를 보여준다. 두 스태머 알고리즘은 서로 다른 알고리즘을 사용하기 떄문이다. 그렇기 때문에 이미 알려진 알고리즘을 사용할 때는, 사용하고자 하는 코퍼스에 스태머를 적용해보고 어떤 스태머가 해당 코퍼스에 적당한지를 판단하고 사용해야 한다.\n",
    "\n",
    "이러한 규칙에 기반한 알고리즘은 종종 제대로된 일반화를 수행하지 못할 수 있다. 어간 추출을 하고나서 일반화가 지나치게 되거나, 또는 덜 되거나 하는 경우이다. 예를 들어 Porter알고리즘에서 `organization`이라는 단어에 대해 어간 추출 작업을 시행한 결과를 보면 아래와 같다.\n",
    "\n",
    "- organization ➡️ organ\n",
    "\n",
    "organization과 organ은 완전히 다른 언어임에도 organization에 대해서 어간 추출을 했는데 organ이라는 단어가 나왔다. organ에 대해 어간 추출을 진행해도 동일한 결과가 나올 것이고, 이는 의미가 동일한 경우에만 같은 단어를 얻기를 원하는 정규화의 목적에는 맞지 않다."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
